{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Quiz3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNxJ5uuvhpHkyOGaSdeDzaB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhmedAsaad272/CNN_classigication-with-Fashion-MNIST/blob/main/Quiz3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WG_4STIHTqN"
      },
      "source": [
        "#%env CUDA_VISIBLE_DEVICES=2\r\n",
        "\r\n",
        "import torch, torchvision\r\n",
        "from torchvision import datasets, models, transforms\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "import time\r\n",
        "from torchsummary import summary\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import os\r\n",
        "\r\n",
        "from PIL import Image"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2VxB0LTHbks"
      },
      "source": [
        "#transforming the PIL Image to tensors\r\n",
        "trainset = torchvision.datasets.FashionMNIST(root = \"./data\", train = True, download = True, transform = transforms.ToTensor())\r\n",
        "testset = torchvision.datasets.FashionMNIST(root = \"./data\", train = False, download = True, transform = transforms.ToTensor())"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSG-mEtpHeAL"
      },
      "source": [
        "#loading the training data from trainset\r\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle = True)\r\n",
        "#loading the test data from testset\r\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False)\r\n"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky4N_jQtkyjd"
      },
      "source": [
        "train_data_size=len(trainloader)\r\n",
        "valid_data_size=len(testloader)\r\n",
        "test_data_size=len(testloader)"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMeAjkG6HhDL"
      },
      "source": [
        "# define our convolutional neural networks\r\n",
        "class Net(nn.Module):\r\n",
        "    def __init__(self, input_size, num_classes):\r\n",
        "        super(Net, self).__init__()\r\n",
        "\r\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\r\n",
        "        torch.nn.init.xavier_uniform_(self.conv1.weight)\r\n",
        "\r\n",
        "        self.conv2 = nn.Conv2d(6, 12, 5)\r\n",
        "        torch.nn.init.xavier_uniform_(self.conv2.weight)\r\n",
        "\r\n",
        "\r\n",
        "        self.pool = nn.MaxPool2d(2,2) # kernel size 2x2, stride = 2\r\n",
        "\r\n",
        "        n_size = self._get_conv_output(input_size)\r\n",
        "\r\n",
        "        self.fc1 = nn.Linear(n_size, 192)\r\n",
        "        torch.nn.init.xavier_uniform_(self.fc1.weight)\r\n",
        "\r\n",
        "        self.fc2 = nn.Linear(192, 120)\r\n",
        "        torch.nn.init.xavier_uniform_(self.fc2.weight)\r\n",
        "\r\n",
        "        self.fc3 = nn.Linear(120, 60)\r\n",
        "        torch.nn.init.xavier_uniform_(self.fc3.weight)\r\n",
        "\r\n",
        "        self.fc4 = nn.Linear(60,10)\r\n",
        "        torch.nn.init.xavier_uniform_(self.fc4.weight)\r\n",
        "\r\n",
        "        self.dropout = nn.Dropout(0.3)\r\n",
        "\r\n",
        "    def _get_conv_output(self, shape):\r\n",
        "        batch_size = 1\r\n",
        "        input = torch.autograd.Variable(torch.rand(batch_size, *shape))\r\n",
        "        output_feat = self._forward_features(input)\r\n",
        "        n_size = output_feat.data.view(batch_size, -1).size(1)\r\n",
        "        return n_size\r\n",
        "\r\n",
        "    def _forward_features(self, x):\r\n",
        "        x = self.pool(F.relu(self.conv1(x)))\r\n",
        "        x = self.pool(F.relu(self.conv2(x)))\r\n",
        "        \r\n",
        "        return x\r\n",
        "      \r\n",
        "    def forward(self, x):\r\n",
        "        x = self._forward_features(x)\r\n",
        "        x = x.view(x.size(0), -1) # flattening\r\n",
        "        x = F.relu(self.fc1(x))        \r\n",
        "        x = F.relu(self.fc2(x))\r\n",
        "        #x = self.dropout(x)\r\n",
        "        x = F.relu(self.fc3(x))        \r\n",
        "        x = self.fc4(x)\r\n",
        "        return x"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swen2RwjHk0c"
      },
      "source": [
        "input_size = (1,28,28)\r\n",
        "num_classes=(10)\r\n",
        "model = Net(input_size , num_classes)\r\n",
        "model = model.to('cuda:0')"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnJhxcJFPyAN",
        "outputId": "a80cc694-66ff-4f58-b7bb-792e8b24f25e"
      },
      "source": [
        "model"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=192, out_features=192, bias=True)\n",
              "  (fc2): Linear(in_features=192, out_features=120, bias=True)\n",
              "  (fc3): Linear(in_features=120, out_features=60, bias=True)\n",
              "  (fc4): Linear(in_features=60, out_features=10, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SscQTkqFiX9M"
      },
      "source": [
        "# Define Optimizer and Loss Function\r\n",
        "learning_rate = 0.1\r\n",
        "loss_func = nn.CrossEntropyLoss()\r\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\r\n",
        "#optimizer = optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj3UFWYmjeAW"
      },
      "source": [
        "def train_and_validate(model, loss_criterion, optimizer, epochs=50):\r\n",
        "    '''\r\n",
        "    Function to train and validate\r\n",
        "    Parameters\r\n",
        "        :param model: Model to train and validate\r\n",
        "        :param loss_criterion: Loss Criterion to minimize\r\n",
        "        :param optimizer: Optimizer for computing gradients\r\n",
        "        :param epochs: Number of epochs (default=10)\r\n",
        "  \r\n",
        "    Returns\r\n",
        "        model: Trained Model with best validation accuracy\r\n",
        "        history: (dict object): Having training loss, accuracy and validation loss, accuracy\r\n",
        "    '''\r\n",
        "    \r\n",
        "    start = time.time()\r\n",
        "    history = []\r\n",
        "    best_acc = 0.0\r\n",
        "\r\n",
        "    for epoch in range(epochs):\r\n",
        "        epoch_start = time.time()\r\n",
        "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\r\n",
        "        \r\n",
        "        # Set to training mode\r\n",
        "        model.train()\r\n",
        "        \r\n",
        "        # Loss and Accuracy within the epoch\r\n",
        "        train_loss = 0.0\r\n",
        "        train_acc = 0.0\r\n",
        "        \r\n",
        "        valid_loss = 0.0\r\n",
        "        valid_acc = 0.0\r\n",
        "        \r\n",
        "        for i, data in enumerate(trainloader):\r\n",
        "\r\n",
        "            inputs, labels = data\r\n",
        "            #moving the input and labels to gpu\r\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\r\n",
        "            \r\n",
        "            # Clean existing gradients\r\n",
        "            optimizer.zero_grad()\r\n",
        "            \r\n",
        "            # Forward pass - compute outputs on input data using the model\r\n",
        "            outputs = model(inputs)\r\n",
        "            \r\n",
        "            # Compute loss\r\n",
        "            loss = loss_criterion(outputs, labels)\r\n",
        "            \r\n",
        "            # Backpropagate the gradients\r\n",
        "            loss.backward()\r\n",
        "            \r\n",
        "            # Update the parameters\r\n",
        "            optimizer.step()\r\n",
        "            \r\n",
        "            # Compute the total loss for the batch and add it to train_loss\r\n",
        "            train_loss += loss.item() * inputs.size(0)\r\n",
        "            \r\n",
        "            # Compute the accuracy\r\n",
        "            ret, predictions = torch.max(outputs.data, 1)\r\n",
        "            correct_counts = predictions.eq(labels.data.view_as(predictions))\r\n",
        "            \r\n",
        "            # Convert correct_counts to float and then compute the mean\r\n",
        "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\r\n",
        "            \r\n",
        "            # Compute total accuracy in the whole batch and add to train_acc\r\n",
        "            train_acc += acc.item() * inputs.size(0)\r\n",
        "            \r\n",
        "            #print(\"Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format(i, loss.item(), acc.item()))\r\n",
        "\r\n",
        "            \r\n",
        "        # Validation - No gradient tracking needed\r\n",
        "        with torch.no_grad():\r\n",
        "\r\n",
        "            # Set to evaluation mode\r\n",
        "            model.eval()\r\n",
        "\r\n",
        "            # Validation loop\r\n",
        "            for j, data in enumerate(testloader):\r\n",
        "                inputs, labels = data\r\n",
        "                #moving the input and labels to gpu\r\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\r\n",
        "\r\n",
        "                # Forward pass - compute outputs on input data using the model\r\n",
        "                outputs = model(inputs)\r\n",
        "\r\n",
        "                # Compute loss\r\n",
        "                loss = loss_criterion(outputs, labels)\r\n",
        "\r\n",
        "                # Compute the total loss for the batch and add it to valid_loss\r\n",
        "                valid_loss += loss.item() * inputs.size(0)\r\n",
        "\r\n",
        "                # Calculate validation accuracy\r\n",
        "                ret, predictions = torch.max(outputs.data, 1)\r\n",
        "                correct_counts = predictions.eq(labels.data.view_as(predictions))\r\n",
        "\r\n",
        "                # Convert correct_counts to float and then compute the mean\r\n",
        "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\r\n",
        "\r\n",
        "                # Compute total accuracy in the whole batch and add to valid_acc\r\n",
        "                valid_acc += acc.item() * inputs.size(0)\r\n",
        "\r\n",
        "                #print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\r\n",
        "            \r\n",
        "        # Find average training loss and training accuracy\r\n",
        "        avg_train_loss = train_loss/train_data_size \r\n",
        "        avg_train_acc = train_acc/train_data_size\r\n",
        "\r\n",
        "        # Find average training loss and training accuracy\r\n",
        "        avg_valid_loss = valid_loss/valid_data_size \r\n",
        "        avg_valid_acc = valid_acc/valid_data_size\r\n",
        "\r\n",
        "        history.append([avg_train_loss, avg_valid_loss, avg_train_acc, avg_valid_acc])\r\n",
        "                \r\n",
        "        epoch_end = time.time()\r\n",
        "    \r\n",
        "        print(\"Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, \\n\\t\\tValidation : Loss : {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s\".format(epoch, avg_train_loss, avg_train_acc*100, avg_valid_loss, avg_valid_acc*100, epoch_end-epoch_start))\r\n",
        "        \r\n",
        "        # Save if the model has best accuracy till now\r\n",
        "        torch.save(model, dataset+'_model_'+str(epoch)+'.pt')\r\n",
        "            \r\n",
        "    return model, history\r\n",
        "    "
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZz7HGbYoQ7H",
        "outputId": "cadccad8-f45d-46d3-eeb5-0fb51396c72b"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "\r\n",
        "# Print the model to be trained\r\n",
        "#summary(resnet50, input_size=(3, 224, 224), batch_size=bs, device='cuda')\r\n",
        "\r\n",
        "# Train the model for 10 epochs\r\n",
        "num_epochs = 50\r\n",
        "trained_model, history = train_and_validate(model, loss_func, optimizer, num_epochs)\r\n",
        "\r\n",
        "torch.save(history, dataset+'_history.pt')"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/50\n",
            "Epoch : 000, Training: Loss: 9.4368, Accuracy: 39.9600%, \n",
            "\t\tValidation : Loss : 9.5229, Accuracy: 40.0000%, Time: 50.7059s\n",
            "Epoch: 2/50\n",
            "Epoch : 001, Training: Loss: 9.4346, Accuracy: 40.1067%, \n",
            "\t\tValidation : Loss : 9.4882, Accuracy: 40.0000%, Time: 50.4686s\n",
            "Epoch: 3/50\n",
            "Epoch : 002, Training: Loss: 9.4370, Accuracy: 40.3933%, \n",
            "\t\tValidation : Loss : 9.3643, Accuracy: 40.0000%, Time: 50.0274s\n",
            "Epoch: 4/50\n",
            "Epoch : 003, Training: Loss: 9.4383, Accuracy: 39.9133%, \n",
            "\t\tValidation : Loss : 9.3143, Accuracy: 40.0000%, Time: 50.5769s\n",
            "Epoch: 5/50\n",
            "Epoch : 004, Training: Loss: 9.4380, Accuracy: 40.2600%, \n",
            "\t\tValidation : Loss : 9.3410, Accuracy: 40.0000%, Time: 50.8564s\n",
            "Epoch: 6/50\n",
            "Epoch : 005, Training: Loss: 9.4366, Accuracy: 39.3667%, \n",
            "\t\tValidation : Loss : 9.4226, Accuracy: 40.0000%, Time: 50.9439s\n",
            "Epoch: 7/50\n",
            "Epoch : 006, Training: Loss: 9.4352, Accuracy: 40.0400%, \n",
            "\t\tValidation : Loss : 9.6015, Accuracy: 40.0000%, Time: 50.6604s\n",
            "Epoch: 8/50\n",
            "Epoch : 007, Training: Loss: 9.4370, Accuracy: 40.6400%, \n",
            "\t\tValidation : Loss : 9.5516, Accuracy: 40.0000%, Time: 50.9037s\n",
            "Epoch: 9/50\n",
            "Epoch : 008, Training: Loss: 9.4441, Accuracy: 39.7000%, \n",
            "\t\tValidation : Loss : 9.4671, Accuracy: 40.0000%, Time: 51.0978s\n",
            "Epoch: 10/50\n",
            "Epoch : 009, Training: Loss: 9.4375, Accuracy: 40.0133%, \n",
            "\t\tValidation : Loss : 9.3483, Accuracy: 40.0000%, Time: 51.7914s\n",
            "Epoch: 11/50\n",
            "Epoch : 010, Training: Loss: 9.4362, Accuracy: 39.3933%, \n",
            "\t\tValidation : Loss : 9.3795, Accuracy: 40.0000%, Time: 51.3091s\n",
            "Epoch: 12/50\n",
            "Epoch : 011, Training: Loss: 9.4367, Accuracy: 40.3267%, \n",
            "\t\tValidation : Loss : 9.7673, Accuracy: 40.0000%, Time: 51.5469s\n",
            "Epoch: 13/50\n",
            "Epoch : 012, Training: Loss: 9.4418, Accuracy: 39.1533%, \n",
            "\t\tValidation : Loss : 9.3581, Accuracy: 40.0000%, Time: 51.9416s\n",
            "Epoch: 14/50\n",
            "Epoch : 013, Training: Loss: 9.4381, Accuracy: 39.3933%, \n",
            "\t\tValidation : Loss : 9.4339, Accuracy: 40.0000%, Time: 52.4496s\n",
            "Epoch: 15/50\n",
            "Epoch : 014, Training: Loss: 9.4365, Accuracy: 39.6067%, \n",
            "\t\tValidation : Loss : 9.4755, Accuracy: 40.0000%, Time: 50.7415s\n",
            "Epoch: 16/50\n",
            "Epoch : 015, Training: Loss: 9.4390, Accuracy: 39.9800%, \n",
            "\t\tValidation : Loss : 9.3420, Accuracy: 40.0000%, Time: 50.3335s\n",
            "Epoch: 17/50\n",
            "Epoch : 016, Training: Loss: 9.4417, Accuracy: 39.2600%, \n",
            "\t\tValidation : Loss : 9.3976, Accuracy: 40.0000%, Time: 51.5511s\n",
            "Epoch: 18/50\n",
            "Epoch : 017, Training: Loss: 9.4410, Accuracy: 39.8533%, \n",
            "\t\tValidation : Loss : 9.5013, Accuracy: 40.0000%, Time: 49.8025s\n",
            "Epoch: 19/50\n",
            "Epoch : 018, Training: Loss: 9.4387, Accuracy: 39.6733%, \n",
            "\t\tValidation : Loss : 9.5676, Accuracy: 40.0000%, Time: 50.5844s\n",
            "Epoch: 20/50\n",
            "Epoch : 019, Training: Loss: 9.4341, Accuracy: 40.8733%, \n",
            "\t\tValidation : Loss : 9.5295, Accuracy: 40.0000%, Time: 50.1803s\n",
            "Epoch: 21/50\n",
            "Epoch : 020, Training: Loss: 9.4354, Accuracy: 40.3200%, \n",
            "\t\tValidation : Loss : 9.6149, Accuracy: 40.0000%, Time: 51.0895s\n",
            "Epoch: 22/50\n",
            "Epoch : 021, Training: Loss: 9.4404, Accuracy: 40.1733%, \n",
            "\t\tValidation : Loss : 9.4374, Accuracy: 40.0000%, Time: 51.6934s\n",
            "Epoch: 23/50\n",
            "Epoch : 022, Training: Loss: 9.4386, Accuracy: 39.4267%, \n",
            "\t\tValidation : Loss : 9.4396, Accuracy: 40.0000%, Time: 52.2956s\n",
            "Epoch: 24/50\n",
            "Epoch : 023, Training: Loss: 9.4383, Accuracy: 40.0133%, \n",
            "\t\tValidation : Loss : 9.4617, Accuracy: 40.0000%, Time: 50.6634s\n",
            "Epoch: 25/50\n",
            "Epoch : 024, Training: Loss: 9.4393, Accuracy: 40.0800%, \n",
            "\t\tValidation : Loss : 9.4613, Accuracy: 40.0000%, Time: 49.7481s\n",
            "Epoch: 26/50\n",
            "Epoch : 025, Training: Loss: 9.4367, Accuracy: 39.5600%, \n",
            "\t\tValidation : Loss : 9.5575, Accuracy: 40.0000%, Time: 50.9753s\n",
            "Epoch: 27/50\n",
            "Epoch : 026, Training: Loss: 9.4373, Accuracy: 39.7067%, \n",
            "\t\tValidation : Loss : 9.3903, Accuracy: 40.0000%, Time: 50.5977s\n",
            "Epoch: 28/50\n",
            "Epoch : 027, Training: Loss: 9.4386, Accuracy: 39.4133%, \n",
            "\t\tValidation : Loss : 9.5453, Accuracy: 40.0000%, Time: 50.1334s\n",
            "Epoch: 29/50\n",
            "Epoch : 028, Training: Loss: 9.4401, Accuracy: 39.7800%, \n",
            "\t\tValidation : Loss : 9.3216, Accuracy: 40.0000%, Time: 50.3209s\n",
            "Epoch: 30/50\n",
            "Epoch : 029, Training: Loss: 9.4309, Accuracy: 40.5267%, \n",
            "\t\tValidation : Loss : 9.4453, Accuracy: 40.0000%, Time: 50.2052s\n",
            "Epoch: 31/50\n",
            "Epoch : 030, Training: Loss: 9.4412, Accuracy: 39.5467%, \n",
            "\t\tValidation : Loss : 9.2866, Accuracy: 40.0000%, Time: 50.8683s\n",
            "Epoch: 32/50\n",
            "Epoch : 031, Training: Loss: 9.4398, Accuracy: 39.5867%, \n",
            "\t\tValidation : Loss : 9.4122, Accuracy: 40.0000%, Time: 50.6068s\n",
            "Epoch: 33/50\n",
            "Epoch : 032, Training: Loss: 9.4368, Accuracy: 40.4867%, \n",
            "\t\tValidation : Loss : 9.4046, Accuracy: 40.0000%, Time: 50.2640s\n",
            "Epoch: 34/50\n",
            "Epoch : 033, Training: Loss: 9.4385, Accuracy: 40.1933%, \n",
            "\t\tValidation : Loss : 9.6349, Accuracy: 40.0000%, Time: 51.1327s\n",
            "Epoch: 35/50\n",
            "Epoch : 034, Training: Loss: 9.4371, Accuracy: 40.0467%, \n",
            "\t\tValidation : Loss : 9.5584, Accuracy: 40.0000%, Time: 51.0676s\n",
            "Epoch: 36/50\n",
            "Epoch : 035, Training: Loss: 9.4326, Accuracy: 40.1267%, \n",
            "\t\tValidation : Loss : 9.5820, Accuracy: 40.0000%, Time: 51.0158s\n",
            "Epoch: 37/50\n",
            "Epoch : 036, Training: Loss: 9.4373, Accuracy: 39.7933%, \n",
            "\t\tValidation : Loss : 9.3292, Accuracy: 40.0000%, Time: 50.8251s\n",
            "Epoch: 38/50\n",
            "Epoch : 037, Training: Loss: 9.4383, Accuracy: 39.8867%, \n",
            "\t\tValidation : Loss : 9.4059, Accuracy: 40.0000%, Time: 49.9925s\n",
            "Epoch: 39/50\n",
            "Epoch : 038, Training: Loss: 9.4426, Accuracy: 39.7133%, \n",
            "\t\tValidation : Loss : 9.4649, Accuracy: 40.0000%, Time: 50.1308s\n",
            "Epoch: 40/50\n",
            "Epoch : 039, Training: Loss: 9.4375, Accuracy: 40.3533%, \n",
            "\t\tValidation : Loss : 9.5509, Accuracy: 40.0000%, Time: 50.9743s\n",
            "Epoch: 41/50\n",
            "Epoch : 040, Training: Loss: 9.4372, Accuracy: 39.8600%, \n",
            "\t\tValidation : Loss : 9.3906, Accuracy: 40.0000%, Time: 51.5688s\n",
            "Epoch: 42/50\n",
            "Epoch : 041, Training: Loss: 9.4274, Accuracy: 39.3000%, \n",
            "\t\tValidation : Loss : 9.5556, Accuracy: 40.0000%, Time: 49.6566s\n",
            "Epoch: 43/50\n",
            "Epoch : 042, Training: Loss: 9.4352, Accuracy: 40.8000%, \n",
            "\t\tValidation : Loss : 9.3936, Accuracy: 40.0000%, Time: 50.9278s\n",
            "Epoch: 44/50\n",
            "Epoch : 043, Training: Loss: 9.4398, Accuracy: 39.3467%, \n",
            "\t\tValidation : Loss : 9.5603, Accuracy: 40.0000%, Time: 50.7545s\n",
            "Epoch: 45/50\n",
            "Epoch : 044, Training: Loss: 9.4359, Accuracy: 39.6733%, \n",
            "\t\tValidation : Loss : 9.3276, Accuracy: 40.0000%, Time: 51.2193s\n",
            "Epoch: 46/50\n",
            "Epoch : 045, Training: Loss: 9.4380, Accuracy: 39.3400%, \n",
            "\t\tValidation : Loss : 9.3537, Accuracy: 40.0000%, Time: 50.7574s\n",
            "Epoch: 47/50\n",
            "Epoch : 046, Training: Loss: 9.4401, Accuracy: 40.7600%, \n",
            "\t\tValidation : Loss : 9.4914, Accuracy: 40.0000%, Time: 51.8034s\n",
            "Epoch: 48/50\n",
            "Epoch : 047, Training: Loss: 9.4418, Accuracy: 40.4667%, \n",
            "\t\tValidation : Loss : 9.2635, Accuracy: 40.0000%, Time: 50.7136s\n",
            "Epoch: 49/50\n",
            "Epoch : 048, Training: Loss: 9.4360, Accuracy: 40.2533%, \n",
            "\t\tValidation : Loss : 9.3214, Accuracy: 40.0000%, Time: 50.4884s\n",
            "Epoch: 50/50\n",
            "Epoch : 049, Training: Loss: 9.4369, Accuracy: 39.7733%, \n",
            "\t\tValidation : Loss : 9.9324, Accuracy: 40.0000%, Time: 50.4280s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrPIem6drUax",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "95156733-7115-4d9c-c334-ca489354b3c2"
      },
      "source": [
        "history = np.array(history)\r\n",
        "plt.plot(history[:,0:2])\r\n",
        "plt.legend(['Tr Loss', 'Val Loss'])\r\n",
        "plt.xlabel('Epoch Number')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.ylim(0,1)\r\n",
        "plt.savefig(dataset+'_loss_curve.png')\r\n",
        "plt.show()"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "lTN3TE1DhDOG",
        "outputId": "f89cc523-b423-4e14-d904-006a68a071a8"
      },
      "source": [
        "plt.plot(history[:,2:4])\r\n",
        "plt.legend(['Tr Accuracy', 'Val Accuracy'])\r\n",
        "plt.xlabel('Epoch Number')\r\n",
        "plt.ylabel('Accuracy')\r\n",
        "plt.ylim(0,1)\r\n",
        "plt.savefig(dataset+'_accuracy_curve.png')\r\n",
        "plt.show()"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZwU9Z3/8denj7mZYWY4VMBAVlwEYURGJKvGg7jRxICJESVrsubQjWsSUbNZczwS48b9ZT0SNeuaENdN3DXgkTU/NB7xAM0vShSMF+AtyqByDDMMzDAzfXx+f1TN2Awz0Bw9I1Pv5+PRj+6qrq76VHd1vbu+1f1tc3dERCS6YgNdgIiIDCwFgYhIxCkIREQiTkEgIhJxCgIRkYhTEIiIRFzBgsDMbjGz9Wb2Yh/3m5ndYGavmdnzZnZkoWoREZG+FfKI4FfAKTu5/1RgfHg5H7ipgLWIiEgfChYE7v44sGknk8wGbvXAUmComR1YqHpERKR3iQFc9ihgTc5wQzju3Z4Tmtn5BEcNlJeXT5swYUK/FCgiMlgsX758o7sP7+2+gQyCvLn7fGA+QH19vS9btmyAKxIR2b+Y2Vt93TeQ3xpaC4zJGR4djhMRkX40kEGwCPhC+O2hGcBmd9+hWUhERAqrYE1DZrYAOAEYZmYNwA+AJIC7/xy4D/gE8BrQBnyxULWIiEjfChYE7j53F/c7cGGhli8i/SeVStHQ0EB7e/tAlxJ5JSUljB49mmQymfdj9ouTxSLywdbQ0MCQIUMYO3YsZjbQ5USWu9PY2EhDQwPjxo3L+3HqYkJE9lp7ezu1tbUKgQFmZtTW1u72kZmCQET2CYXAB8OevA4KAhGRiFMQiMh+r7GxkSOOOIIjjjiCAw44gFGjRnUPd3Z29vm4efPmMWrUKLLZbD9W+8Gjk8Uist+rra3l2WefBeDyyy+noqKCb37zm933p9NpEontd3fZbJa7776bMWPG8Nhjj3HiiScWpLbelv1BoyMCERmUzj33XL761a9y9NFH861vfWuH+5csWcKkSZO44IILWLBgQff4devW8elPf5q6ujrq6up44oknALj11luZMmUKdXV1fP7zn+9exl133dX92IqKiu55H3fcccyaNYuJEycCcPrppzNt2jQmTZrE/Pnzux/zwAMPcOSRR1JXV8fMmTPJZrOMHz+eDRs2AEFgHXLIId3DhfDBjikR2e/88J4VrHynZZ/Oc+JBlfzgU5N2+3ENDQ088cQTxOPxHe5bsGABc+fOZfbs2XznO98hlUqRTCb5xje+wfHHH8/dd99NJpNh69atrFixgh/96Ec88cQTDBs2jE2bdtaxcuCZZ57hxRdf7P4a5y233EJNTQ3btm3jqKOO4owzziCbzXLeeefx+OOPM27cODZt2kQsFuOcc87htttuY968eTz88MPU1dUxfHiv/cXtEzoiEJFB68wzz+w1BDo7O7nvvvs4/fTTqays5Oijj+bBBx8E4NFHH+WCCy4AIB6PU1VVxaOPPsqZZ57JsGHDAKipqdnlsqdPn77dd/lvuOEG6urqmDFjBmvWrOHVV19l6dKlfPSjH+2ermu+X/rSl7j11luBIEC++MXCdrygIwIR2af25JN7oZSXl/c6/sEHH6S5uZnJkycD0NbWRmlpKaeddtpuzT+RSHSfaM5ms9udmM5d9pIlS3j44Yd58sknKSsr44QTTtjpd/3HjBnDyJEjefTRR3nqqae47bbbdquu3aUjAhGJnAULFnDzzTezevVqVq9ezZtvvslDDz1EW1sbM2fO5Kabgj9MzGQybN68mZNOOok777yTxsZGgO6mobFjx7J8+XIAFi1aRCqV6nV5mzdvprq6mrKyMl566SWWLl0KwIwZM3j88cd58803t5svwFe+8hXOOeecPo9q9iUFgYhESltbGw888ACf/OQnu8eVl5dz7LHHcs8993D99dezePFiJk+ezLRp01i5ciWTJk3iu9/9Lscffzx1dXVccsklAJx33nk89thj1NXV8eSTT/Z5BHLKKaeQTqc57LDDuOyyy5gxYwYAw4cPZ/78+XzmM5+hrq6Os846q/sxs2bNYuvWrQVvFgKwoO+3/Yf+mEbkg2fVqlUcdthhA13GoLJs2TIuvvhi/vjHP+72Y3t7PcxsubvX9za9zhGIiHzA/PjHP+amm24q+LmBLmoaEhH5gLnssst46623OPbYY/tleQoCEZGIUxCIiEScgkBEJOIUBCIiEacgEJH93oknntjdRUSX6667rruriN6ccMIJ9PVV9I0bN5JMJvn5z3++T+v8oFIQiMh+b+7cuSxcuHC7cQsXLmTu3Ll7NL8777yTGTNmbNcraSGk0+mCzj9fCgIR2e999rOf5fe//313Xz+rV6/mnXfe4bjjjuOCCy6gvr6eSZMm8YMf/CCv+S1YsIBrr72WtWvX0tDQ0D2+t66oe+u2evXq1Rx++OHdj7vmmmu4/PLLgeBIZN68edTX13P99ddzzz33cPTRRzN16lQ+9rGPsW7dOoDuXxVPnjyZKVOm8Nvf/pZbbrmFefPmdc/3l7/8JRdffPFePXegH5SJyL52/2Xw3gv7dp4HTIZTf9zn3TU1NUyfPp3777+f2bNns3DhQubMmYOZceWVV1JTU0Mmk2HmzJk8//zzTJkypc95rVmzhnfffZfp06czZ84cbr/9di699NI+u6Lurdvqpqamna5OZ2dnd7NUU1MTS5cuxcy4+eabueqqq7j22mv5l3/5F6qqqnjhhRe6p0smk1x55ZVcffXVJJNJ/uu//otf/OIXu/ts7kBHBCIyKOQ2D+U2C91xxx0ceeSRTJ06lRUrVrBy5cqdzuf2229nzpw5AJx99tndzUN9dUXdW7fVu5Lbp1BDQwMf//jHmTx5MldffTUrVqwA4OGHH+bCCy/snq66upqKigpOOukk7r33Xl566SVSqVR3D6p7Q0cEIrJv7eSTeyHNnj2biy++mGeeeYa2tjamTZvGm2++yTXXXMPTTz9NdXU155577k67f4agWei9997r7t7hnXfe4dVXX92tWnK7pwZ2WGZu53Rf//rXueSSS5g1axZLlizpbkLqy1e+8hX+9V//lQkTJuyzDul0RCAig0JFRQUnnngiX/rSl7qPBlpaWigvL6eqqop169Zx//3373Qer7zyClu3bmXt2rXdXVR/+9vfZsGCBX12Rd1bt9UjR45k/fr1NDY20tHRwb333tvnMjdv3syoUaMA+PWvf909/uSTT+bGG2/sHu5qbjr66KNZs2YNv/nNb/b4ZHhPCgIRGTTmzp3Lc889172DrKurY+rUqUyYMIHPfe5zHHPMMTt9/IIFC/j0pz+93bgzzjiDBQsW9NkVdW/dVieTSb7//e8zffp0Tj75ZCZMmNDnMi+//HLOPPNMpk2b1t3sBPC9732PpqYmDj/8cOrq6li8eHH3fXPmzOGYY46hurp6t5+j3qgbahHZa+qGun+ddtppXHzxxcycObPX+3e3G2odEYiI7Ceam5s59NBDKS0t7TME9oROFouI7CeGDh3KK6+8ss/nqyMCEdkn9rdm5sFqT14HBYGI7LWSkhIaGxsVBgPM3WlsbKSkpGS3HqemIRHZa6NHj6ahoYENGzYMdCmRV1JSwujRo3frMQoCEdlryWSScePGDXQZsofUNCQiEnEFDQIzO8XMXjaz18zssl7uP9jMFpvZX8zseTP7RCHrERGRHRUsCMwsDtwInApMBOaa2cQek30PuMPdpwJnA/9RqHpERKR3hTwimA685u5vuHsnsBCY3WMaByrD21XAOwWsR0REelHIIBgFrMkZbgjH5bocOMfMGoD7gK/3NiMzO9/MlpnZMn0rQURk3xrok8VzgV+5+2jgE8B/m9kONbn7fHevd/f64cOH93uRIiKDWSGDYC0wJmd4dDgu15eBOwDc/UmgBBiGiIj0m0IGwdPAeDMbZ2ZFBCeDF/WY5m1gJoCZHUYQBGr7ERHpRwULAndPA18DHgRWEXw7aIWZXWFms8LJLgXOM7PngAXAua7fqIuI9KuC/rLY3e8jOAmcO+77ObdXAjv/pwgRESmogT5ZLCIiA0xBICIScQoCEZGIUxCIiEScgkBEJOIUBCIiEacgEBGJOAWBiEjEKQhERCJOQSAiEnEKAhGRiFMQiIhEnIJARCTiFAQiIhGnIBARiTgFgYhIxCkIREQiTkEgIhJxCgIRkYhTEIiIRJyCQEQk4hQEIiIRpyAQEYk4BYGISMQpCEREIk5BICIScQoCEZGIUxCIiEScgkBEJOIUBCIiEacgEBGJOAWBiEjEKQhERCJOQSAiEnEFDQIzO8XMXjaz18zssj6mmWNmK81shZn9ppD1iIjIjhKFmrGZxYEbgZOBBuBpM1vk7itzphkPfBs4xt2bzGxEoeoREZHeFfKIYDrwmru/4e6dwEJgdo9pzgNudPcmAHdfX8B6RESkF4UMglHAmpzhhnBcrkOBQ83sT2a21MxO6W1GZna+mS0zs2UbNmwoULkiItE00CeLE8B44ARgLvBLMxvacyJ3n+/u9e5eP3z48H4uUURkcNtlEJjZp8xsTwJjLTAmZ3h0OC5XA7DI3VPu/ibwCkEwiIhIP8lnB38W8KqZXWVmE3Zj3k8D481snJkVAWcDi3pM8zuCowHMbBhBU9Ebu7EMERHZS7sMAnc/B5gKvA78ysyeDNvsh+zicWnga8CDwCrgDndfYWZXmNmscLIHgUYzWwksBv7J3Rv3Yn1ERGQ3mbvnN6FZLfB5YB7Bjv0Q4AZ3/1nhyttRfX29L1u2rD8XKSKy3zOz5e5e39t9+ZwjmGVmdwNLgCQw3d1PBeqAS/dloSIi0v/y+UHZGcBP3f3x3JHu3mZmXy5MWSIi0l/yCYLLgXe7BsysFBjp7qvd/ZFCFSYiIv0jn28N3Qlkc4Yz4TgRERkE8gmCRNhFBADh7aLClSQiIv0pnyDYkPN1T8xsNrCxcCWJiEh/yuccwVeB28zs3wEj6D/oCwWtSkRE+s0ug8DdXwdmmFlFOLy14FWJiEi/yev/CMzsk8AkoMTMAHD3KwpYl4iI9JN8flD2c4L+hr5O0DR0JvChAtclIiL9JJ+TxX/j7l8Amtz9h8BHCDqHExGRQSCfIGgPr9vM7CAgBRxYuJJERKQ/5XOO4J7wz2KuBp4BHPhlQasSEZF+s9MgCP+Q5hF3bwZ+a2b3AiXuvrlfqhMRkYLbadOQu2eBG3OGOxQCIiKDSz7nCB4xszOs63ujIiIyqOQTBP9A0Mlch5m1mNkWM2spcF0iItJP8vll8U7/klJERPZvuwwCM/tob+N7/lGNiIjsn/L5+ug/5dwuAaYDy4GTClKRiIj0q3yahj6VO2xmY4DrClaRiIj0q3xOFvfUABy2rwsREZGBkc85gp8R/JoYguA4guAXxiIiMgjkc45gWc7tNLDA3f9UoHpERKSf5RMEdwHt7p4BMLO4mZW5e1thSxMRkf6Q1y+LgdKc4VLg4cKUIyIi/S2fICjJ/XvK8HZZ4UoSEZH+lE8QtJrZkV0DZjYN2Fa4kkREpD/lc45gHnCnmb1D8FeVBxD8daWIiAwC+fyg7GkzmwD8dTjqZXdPFbYsERHpL/n8ef2FQLm7v+juLwIVZvaPhS9NRET6Qz7nCM4L/6EMAHdvAs4rXEkiItKf8gmCeO6f0phZHCgqXEkiItKf8jlZ/ABwu5n9Ihz+B+D+wpUkIiL9KZ8g+GfgfOCr4fDzBN8cEhGRQSCfbw1lzezPwF8Bc4BhwG/zmbmZnQJcD8SBm939x31MdwZBVxZHufuy3qaJkua2Tla+08KYmjLG1Oi3e31ZvbGV/1n6Fs+83cQhIyo4fFQVkw6q4rADh1BWlM9nnP1bZzpLUWJPOhCWznSWO5evYW3TNs6Z8SEOGlq66wftpo50hv99Zi2rG1sZOaSEkZUlHFBVzIghJYyoLKY4Ed/ny9xTfb5bzOxQYG542QjcDuDuJ+Yz4/Bcwo3AyQRdVz9tZovcfWWP6YYAFwF/3pMV2FOZrNPamWZre5ot7Wk2bOlg/ZZ21rV0sK6lnQ1bOtiwtYPhFcWMH1nBoSOHcOjICj5UW04y/v6br6U9xdqmbcGleRuJuHHShBEcWJXfhrWtM8OKdzbz7Jpmnm/YzHMNzbzV+H43TlNGV/GJyQfyicMP5ODafRMK7akMj72ygSdfb6R+bDV/O/GA/WaHks06S15Zz61PvsWSlzeQiBlTRlfx8Kr13LGsAYCYwYeHV3DYgZXUlCUpL05QXpygIud60kGVexSymayTymTpzGRJpbPEY8bQsv45ZbaptZMnXt/In15r5InXN/L2pjamj63hU3UHcerhB1BbUZz3vLJZ59mGZv6wYh1/WPke61s6GFFZzAGVwQ5rRGUxI4eUMHxIMRXFCSpKEpQXdT2HccqKEqSyWTrT71860llSmSw15UWMGFJMIr7vtqnWjjTPrWlm+VtNvLxuCwcNLeXQkUOYcMAQDhlRQUkyv51qJussem4tP33oVd7e1IYZ3PzHN5k7fQz/eOIhjKws2eta21MZ7li2hpuWvM67m9tJxIx01neYbmhZkuqyoh2uayuK+KvhwT7n4Joy4jHrZSn7lrnvWCCAmWWBPwJfdvfXwnFvuPuH85qx2UeAy9394+HwtwHc/f/0mO464CGCf0L75q6OCOrr633Zst0/aHj5Vxey7e2/kMlCxp1sH+sNEDcjmYiRjBmdmWAD764XKEnGMaAjkyXTywsMUF6UoKa8iOryJKXJOEbwYqYyWba0p9nSnqKlI01bR7q7j++ieKx7Z1VeHKetM0Pj1k5aO9MAlBXFqS0vpiQZ637jdWbefyM6BG/arktJgnh4nj/jTnNbJ42tnTS3pci6YwT9iydjMUZUFjNiyJ59Ssl6sHPsCGtqT2WC26kMqaxTXhSnsjRJZUmSkmSs+7no4jgd6SytHWm2dqRxh3jMSMQs5zpGa2eadS3tdKSzJOMxRg4pZkRlCUXxGI7TmcnS2pGhtSNNW2eGts406ayTzTq9vUrFiRiVJUmqSpNUliYpCndcWQ8/JHSkae3IsLUjTUc6Q1+bTDIWo6w4TllRsIMsK4pTGu6YMu5kwhq6bsdjRlE8RjIeI2Y7vsm71qUjFTyfbR1pNrenaOvMAMH2WVmaoCQZp6ktRXsqGF9VmqS2vIia8iISsdh28wvWC7a0p2hq7WRTW4pUJosBlaXBNtq1LaUy729Pe6MoHqM4EaMoEaM4ESdmQQ3Z8P3XdRvY4bWOxwx3p7UjzZbw9cydbyqb3e71KEnEKS2KU14U7w7+ovj2z0FTW4o1m9rYlspQVhRnTE0ZZck4a5u3sWFLBxiMHFLCQUNLt3ts1+NTmWA7T8SMosSO23HWnfVbOnineRudmSxDihOMri6jsjRBOuvbPbfBBwknnc2Szjip8Dqd3X7fZAalyThlyTilRQlKDz6CmjN+skevh5ktd/f63u7b2fHzZ4CzgcVm9gCwENidaBoFrMkZbgCO7lHYkcAYd/+9meX+JSY9pjuf4DwFBx988G6U8L6SZJxYcYJ4uMHFLbiOhcNdb8yiRKx759kl4862zgzbUsHOZVu4UQ4pTVKc2H5jz2SzbGpN0dTWyZqmNtY0BRtpeXGc1s5M95vWDCqKEhxYVUpFSbDj7rnxDS2Fg6pK6Uhn2NQa7MTXNL1/tBCzYIMsiseoLE0CsLUjTVNbZ/c0pck4RYkYLe0p3IM33LCKYGdRWZJk87YU61raWdscHNFUlyUZUVlCSSJOOpMNNv5ssAGnwzdCOuvhRhuMy/SyhyyKxyhOxihNxmlpT9PY2tk9vrIkQUVJklQmG+5s092fmAyIxazPgB1SnODgmjKqy4uI5WyOhlEcj1NcFqemxyd0x3EPPg1mPKh9a0eazdtSbGrrZMPWju7nyoztdjrJeIyK4jjVZUliZpgFy4oZmBnZcNto60zzXkuqz7DoS9dOJQgzwp1/ZrudsBkMKU4yprqIytIkFcWJ7p3QwTXe/YGhsbWDNza28sbGVmJm3evdU8yMoaVJasqDT6G5oZH7nKXDo59MNjfM6B7ueg62u8a6jxQ60lk600GQbmrtxHn/9Y1hxGLB4yCYZ7rHzh2C0KsoTjBqaBFDwvdJIhYEf3sqS1tnEBLBa5DZbttPxmOUF8UpK07Qsi3F1o40JYk440dUUFNe1P0cfnhYBQcNLWVt0zbea2ln/ZZ2asuLcfftPmz1fCqL4l3v+2Df0djaSSoMgL8aXkFl6fuvUzJmJIvyO0LK5GxTwT4nQ0t7mo2tndRUd1CT11x2T59B4O6/A35nZuXAbIKuJkaY2U3A3e7+h71ZsJnFgJ8A5+5qWnefD8yH4IhgT5b3ob+7YU8eBgQnOCrCSz5GhZf3Nrfz0Kp1/GHFe7z83hYmj6niqHE1HDW2msNHVeX96bsYODC8vLe5neZtnRxYVUplSQLr5RPl5rYUzzY085e3m3h2TTMNTds4ZmItp04+kKlja7Y71KwOLw1NbSx46m1uf3oNG9/u3GGeEOyEq8uLqK4sorqXw9kx1WUcXFMWfKLKaWpyd97Y2MqTrzey9I3gsrGpk5jBoSOHMGV8FVNGD+WIMUM5dOQQihIxsllna2ealm0pWralaWlPUVtexPiRQ/J8Fd5n4SUGJMNxFQTfeMhknRfXbuZPr2/kydcbAagbPZQpo4OaDqjKv6kgncny5sZWVr7bwusbWknGbLsmqfLi4NPq1vbgyGZdS0ew42lp572WduIxY0x1GaNrShlTHZwfGl1dyujq0j63FQPKw8sYd55r2Mwjq9bRnsqEn6wJrs1IxI1DRw7huPHDdtmUYuFzldzpVPnLhsEe20UzR0c6w5b24HXPOowbVt5r04gRdINcCtTmjN/akWbVuy28uHYzL64Nrl9dv4UDKku46FPjOePI0b02WZUQnASNbWzlZ4+8ygMr3qOmvIiDaks5aGgJBw4t5aCqoKmsqS3Fu83bWNvczjvN23hn8zbebW5n6pihXPSx8Uz8cG2v78t89bW/2dKe6vUIcl/os2mo14nNqoEzgbPcfeYupt1p05CZVQGvA109mx4AbAJm7ax5aE+bhiQ/neksi19eT2tHmtqKYmrLg518TXnRPju55e40NG2jtqIoEid1ZWC1pzIk47GCtrW7+17t/PvDzpqGdisIdnOhCeAVYCawFnga+Jy7r+hj+iUU8ByBiEiU7SwICvZVEXdPA18DHgRWAXe4+wozu8LMZhVquSIisnsKelzu7vcB9/UY9/0+pj2hkLWIiEjv9o8vj4uISMEoCEREIk5BICIScQoCEZGIUxCIiEScgkBEJOIUBCIiEacgEBGJOAWBiEjEKQhERCJOQSAiEnEKAhGRiFMQiIhEnIJARCTiFAQiIhGnIBARiTgFgYhIxCkIREQiTkEgIhJxCgIRkYhTEIiIRJyCQEQk4hQEIiIRpyAQEYk4BYGISMQpCEREIk5BICIScQoCEZGIUxCIiEScgkBEJOIUBCIiEacgEBGJOAWBiEjEKQhERCKuoEFgZqeY2ctm9pqZXdbL/ZeY2Uoze97MHjGzDxWyHhER2VHBgsDM4sCNwKnARGCumU3sMdlfgHp3nwLcBVxVqHpERKR3hTwimA685u5vuHsnsBCYnTuBuy9297ZwcCkwuoD1iIhILwoZBKOANTnDDeG4vnwZuL+3O8zsfDNbZmbLNmzYsA9LFBGRD8TJYjM7B6gHru7tfnef7+717l4/fPjw/i1ORGSQSxRw3muBMTnDo8Nx2zGzjwHfBY53944C1iMiIr0o5BHB08B4MxtnZkXA2cCi3AnMbCrwC2CWu68vYC0iItKHggWBu6eBrwEPAquAO9x9hZldYWazwsmuBiqAO83sWTNb1MfsRESkQArZNIS73wfc12Pc93Nuf6yQyxcRkV37QJwsFhGRgaMgEBGJOAWBiEjEKQhERCJOQSAiEnEKAhGRiFMQiIhEnIJARCTiFAQiIhGnIBARiTgFgYhIxCkIREQiTkEgIhJxCgIRkYhTEIiIRJyCQEQk4hQEIiIRpyAQEYk4BYGISMQpCEREIk5BICIScQoCEZGIUxCIiEScgkBEJOIUBCIiEacgEBGJOAWBiEjEKQhERCJOQSAiEnEKAhGRiFMQiIhEnIJARCTiFAQiIhGnIBARiTgFgYhIxBU0CMzsFDN72cxeM7PLerm/2MxuD+//s5mNLWQ9IiKyo4IFgZnFgRuBU4GJwFwzm9hjsi8DTe5+CPBT4N8KVY+IiPSukEcE04HX3P0Nd+8EFgKze0wzG/h1ePsuYKaZWQFrEhGRHhIFnPcoYE3OcANwdF/TuHvazDYDtcDG3InM7Hzg/HBwq5m9vIc1Des574iI6npDdNdd6x0t+az3h/q6o5BBsM+4+3xg/t7Ox8yWuXv9PihpvxLV9YborrvWO1r2dr0L2TS0FhiTMzw6HNfrNGaWAKqAxgLWJCIiPRQyCJ4GxpvZODMrAs4GFvWYZhHw9+HtzwKPursXsCYREemhYE1DYZv/14AHgThwi7uvMLMrgGXuvgj4T+C/zew1YBNBWBTSXjcv7aeiut4Q3XXXekfLXq236QO4iEi06ZfFIiIRpyAQEYm4yATBrrq7GCzM7BYzW29mL+aMqzGzh8zs1fC6eiBrLAQzG2Nmi81spZmtMLOLwvGDet3NrMTMnjKz58L1/mE4flzYbctrYTcuRQNdayGYWdzM/mJm94bDg369zWy1mb1gZs+a2bJw3F5t55EIgjy7uxgsfgWc0mPcZcAj7j4eeCQcHmzSwKXuPhGYAVwYvsaDfd07gJPcvQ44AjjFzGYQdNfy07D7liaC7lwGo4uAVTnDUVnvE939iJzfDuzVdh6JICC/7i4GBXd/nOAbWLlyu/L4NXB6vxbVD9z9XXd/Jry9hWDnMIpBvu4e2BoOJsOLAycRdNsCg3C9AcxsNPBJ4OZw2IjAevdhr7bzqARBb91djBqgWgbCSHd/N7z9HjByIIsptLAX26nAn4nAuofNI88C64GHgNeBZndPh5MM1u39OuBbQDYcriUa6+3AH8xsedj9DsUJKDYAAARnSURBVOzldr5fdDEh+467u5kN2u8Mm1kF8Ftgnru35PZhOFjX3d0zwBFmNhS4G5gwwCUVnJmdBqx39+VmdsJA19PPjnX3tWY2AnjIzF7KvXNPtvOoHBHk093FYLbOzA4ECK/XD3A9BWFmSYIQuM3d/zccHYl1B3D3ZmAx8BFgaNhtCwzO7f0YYJaZrSZo6j0JuJ7Bv964+9rwej1B8E9nL7fzqARBPt1dDGa5XXn8PfB/B7CWggjbh/8TWOXuP8m5a1Cvu5kND48EMLNS4GSC8yOLCbptgUG43u7+bXcf7e5jCd7Pj7r73zHI19vMys1sSNdt4G+BF9nL7Twyvyw2s08QtCl2dXdx5QCXVBBmtgA4gaBb2nXAD4DfAXcABwNvAXPcvecJ5f2amR0L/BF4gffbjL9DcJ5g0K67mU0hODkYJ/hgd4e7X2FmHyb4pFwD/AU4x907Bq7Swgmbhr7p7qcN9vUO1+/ucDAB/MbdrzSzWvZiO49MEIiISO+i0jQkIiJ9UBCIiEScgkBEJOIUBCIiEacgEBGJOAWB7NfMLBP2wth12WedypnZ2NxeXHcy3eVm1hb+0rNr3NadPWZf1yCyN9TFhOzvtrn7EQNdBLARuBT454EuJJeZJXL63hHplY4IZFAK+2y/Kuy3/SkzOyQcP9bMHjWz583sETM7OBw/0szuDvv1f87M/iacVdzMfhn29f+H8Ne7vbkFOMvManrUsd0nejP7ppldHt5eYmY/NbNlZrbKzI4ys/8N+5T/Uc5sEmZ2WzjNXWZWFj5+mpk9FnY+9mBOFwNLzOy6sK/6i/b+2ZTBTkEg+7vSHk1DZ+Xct9ndJwP/TvCrcoCfAb929ynAbcAN4fgbgMfCfv2PBFaE48cDN7r7JKAZOKOPOrYShMHu7ng7wz7lf07QLcCFwOHAueGvRQH+GvgPdz8MaAH+MexX6WfAZ919Wrjs3F/LF7l7vbtfu5v1SASpaUj2dztrGlqQc/3T8PZHgM+Et/8buCq8fRLwBejuzXNz+C9Pb7r7s+E0y4GxO6nlBuBZM7tmN+rv6vPqBWBFV1fCZvYGQUeJzcAad/9TON3/AN8AHiAIjIfCHlbjwLs58719N2qQiFMQyGDmfdzeHbn91GSAvpqGcPdmM/sNwaf6Lmm2P/Iu6WP+2R7LyvL++7Nn7Q4YQXB8pI9yWvuqU6QnNQ3JYHZWzvWT4e0nCHqrBPg7go7qIPh7vwug+49eqvZwmT8B/oH3d+LrgBFmVmtmxcBpezDPg82sa4f/OeD/AS8Dw7vGm1nSzCbtYc0ScQoC2d/1PEfw45z7qs3seYJ2+4vDcV8HvhiO/zzvt+lfBJxoZi8QNAHt0X9au/tGgt4hi8PhFHAF8BTBv4e91Pej+/QywX8wrwKqgZvCv1z9LPBvZvYc8CzwNzuZh0if1PuoDErhH5bUhztmEdkJHRGIiEScjghERCJORwQiIhGnIBARiTgFgYhIxCkIREQiTkEgIhJx/x8uv9bajff2mAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}